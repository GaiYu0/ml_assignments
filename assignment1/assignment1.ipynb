{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/matplotlib/backends/backend_gtk3agg.py:18: UserWarning: The Gtk3Agg backend is known to not work on Python 3.x with pycairo. Try installing cairocffi.\n",
      "  \"The Gtk3Agg backend is known to not work on Python 3.x with pycairo. \"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 & Question 2\n",
    "    Please refer to utility.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-process data\n",
    "training_X, training_Y, validation_X, validation_Y, test_X, test_Y, vocabulary = format_dataset(X=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 3\n",
    "    Perceptron_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error(W, X, Y):\n",
    "    return np.sum(np.dot(X, W) * Y < 0)\n",
    "def perceptron_error(W, X, Y):\n",
    "    N, D = X.shape\n",
    "    return error(W, X, Y) / N\n",
    "def perceptron_train(W, X, Y, learning_rate=1, logging_interval=1, maximum_n_iterations=None):\n",
    "    N, D = X.shape\n",
    "    total_n_errors = 0\n",
    "    n_iterations = 0\n",
    "    while True:\n",
    "        predictions = np.dot(X, W)\n",
    "        update_filter = predictions * Y < 0\n",
    "        gradient = np.mean((update_filter * Y).reshape((N, 1)) * X, axis=0)\n",
    "        W += learning_rate * gradient\n",
    "        n_iterations += 1\n",
    "        if maximum_n_iterations is not None and maximum_n_iterations < n_iterations: break\n",
    "        n_errors = np.sum(update_filter)\n",
    "        if n_errors == 0: break\n",
    "        else: total_n_errors += n_errors\n",
    "        if isinstance(logging_interval, int):\n",
    "            if n_iterations % logging_interval == 0: print('update %d errors %d' % (n_iterations, n_errors))\n",
    "    return W, n_errors, n_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update 1 errors 2421\n",
      "update 2 errors 1666\n",
      "update 3 errors 1571\n",
      "update 4 errors 1457\n"
     ]
    }
   ],
   "source": [
    "D = len(vocabulary) # dimension of feature vector\n",
    "W = np.random.normal(0, 1, D) # initialize weights\n",
    "N_TRAINING_SAMPLES = 4000\n",
    "W, n_errors, n_iterations = perceptron_train(W, training_X[:N_TRAINING_SAMPLES], training_Y[:N_TRAINING_SAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check whether there is no error on training set\n",
    "perceptron_error(W, training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test perceptron on validation set\n",
    "perceptron_error(W, validation_X, validation_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = W.tolist()\n",
    "sorted_weights = sorted(weights)\n",
    "N = 12\n",
    "negative_N = tuple(vocabulary[weights.index(weight)] for weight in sorted_weights[:N])\n",
    "positive_N = tuple(vocabulary[weights.index(weight)] for weight in sorted_weights[len(sorted_weights) - N:])\n",
    "print('%d most negative words:' % N, *negative_N)\n",
    "print('%d most positive words:' % N, *positive_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 & Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# record number of iteration and validation error\n",
    "n_update_table = {}\n",
    "validation_error_table = []\n",
    "for N_TRAINING_SAMPLES in (100, 200, 400, 800, 2000, 4000):\n",
    "    W = np.random.normal(0, 1, D)\n",
    "    W, n_iterations = perceptron_train(\n",
    "        W,\n",
    "        training_X[:N_TRAINING_SAMPLES],\n",
    "        training_Y[:N_TRAINING_SAMPLES],\n",
    "        logging_interval=None\n",
    "    )\n",
    "    n_update_table[N_TRAINING_SAMPLES] = n_iterations\n",
    "    validation_error_table.append(perceptron_error(W, validation_X, validation_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot number of iteration\n",
    "pl.plot(list(n_update_table.keys()), list(n_update_table.values()), 'bo')\n",
    "pl.xlabel('number of training samples')\n",
    "pl.ylabel('number of updates')\n",
    "pl.title('number of updates required for 0 training error')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot validation error\n",
    "pl.plot(list(validation_error_table.keys()), list(validation_error_table.values()), 'bo')\n",
    "pl.xlabel('number of training samples')\n",
    "pl.ylabel('validation error')\n",
    "pl.title('validation error')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.random.normal(0, 1, D)\n",
    "N_TRAINING_SAMPLES = 4000\n",
    "MAXIMUM_n_iterations = 200\n",
    "W, n_iterations = perceptron_train(\n",
    "    W,\n",
    "    training_X[:N_TRAINING_SAMPLES],\n",
    "    training_Y[:N_TRAINING_SAMPLES],\n",
    "    maximum_n_iterations=MAXIMUM_n_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation error\n",
    "perceptron_error(W, validation_X, validation_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "    Provided X equaling 1200, the data is not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "training_X, training_Y, validation_X, validation_Y, test_X, test_Y, vocabulary = format_dataset(X=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of identical data points labelled differently\n",
    "positive_set = set(tuple(point) for point in training_X[training_Y == 1].tolist())\n",
    "negative_set = set(tuple(point) for point in training_X[training_Y == -1].tolist())\n",
    "len(positive_set & negative_set)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
